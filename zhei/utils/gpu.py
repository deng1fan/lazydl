from nvitop import Device, GpuProcess, NA, colored, select_devices
from zhei.utils.log import get_logger
import time
from zhei.utils.catch_error import print_error_info
import json
import os
import datetime
from redis import Redis
from zhei.utils.notice import notice

log = get_logger(__name__)


def set_config_gpus(config):
    redis_client = RedisClient()

    self_occupied_gpus = redis_client.get_self_occupied_gpus()

    if (
        config.use_gpu
        and isinstance(config.visible_cuda, str)
        and "auto_select_" in config.visible_cuda
    ):
        # å¦‚æœæ˜¯è‡ªåŠ¨é€‰æ‹©GPU
        min_count = int(config.visible_cuda.split("auto_select_")[-1])
        gpus = select_devices(
            format="index",
            min_count=min_count,
            min_free_memory=config.cuda_min_free_memory,
            max_memory_utilization=config.cuda_max_memory_utilization,
        )
        available_gpus = list(set(gpus) - self_occupied_gpus)
        if len(available_gpus) > 0 and len(available_gpus) >= min_count and len(self_occupied_gpus) < config.limit_the_amount_of_gpu_you_can_use:
            # æœ‰è¶³å¤Ÿå¯ç”¨GPU
            config.wait_gpus = False
            config.visible_cuda = available_gpus[:min_count]
            config.want_gpu_num = len(config.visible_cuda)
            config.default_device = f"cuda:{config.visible_cuda[0]}"
            config.task_id = redis_client.register_gpus(config)
            log.info(f"è‡ªåŠ¨é€‰æ‹©GPUï¼š{str(config.visible_cuda)}")
        else:
            # å¯ç”¨GPUä¸è¶³
            if config.wait_gpus:
                # æ’é˜Ÿ
                config.task_id, wait_num = redis_client.join_wait_queue(config)
                # å‘é€é’‰é’‰é€šçŸ¥
                try:
                    notice(
                        f"{config.comet_name} åŠ å…¥æ’é˜Ÿé˜Ÿåˆ—ï¼å‰æ–¹è¿˜æœ‰{wait_num}ä¸ªä»»åŠ¡ğŸš¶ğŸ»â€ğŸ§‘ğŸ»â€ğŸ¦¼ğŸš¶ğŸ‘©â€ğŸ¦¯ğŸ‘¨ğŸ»â€ğŸ¦¯", config)
                except Exception as e:
                    print_error_info(e)
                    log.info(f"å‘é€é’‰é’‰é€šçŸ¥å¤±è´¥: {e}")
            else:
                # ä¸æ’é˜Ÿ
                raise Exception("å¯ç”¨GPUæ•°é‡ä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨æ’é˜ŸåŠŸèƒ½ï¼")
    elif config.use_gpu:
        # å¦‚æœæŒ‡å®šäº†GPU
        # è½¬æ¢æˆç›¸å¯¹ç´¢å¼•
        reserve_gpus = [i for i, _ in enumerate(config.visible_cuda)]
        # reserve_gpus = config.visible_cuda
        min_count = len(reserve_gpus)
        gpu_all_free = True
        for gpu in reserve_gpus:
            if Device.cuda.from_cuda_indices(gpu)[0].physical_index in self_occupied_gpus:
                gpu_all_free = False
        if len(self_occupied_gpus) >= config.limit_the_amount_of_gpu_you_can_use:
            gpu_all_free = False
        if not config.wait_gpus and not gpu_all_free:
            raise Exception("æŒ‡å®šGPUå¹¶æœªå…¨éƒ¨ç©ºé—²ï¼Œå»ºè®®ä½¿ç”¨æ’é˜ŸåŠŸèƒ½ï¼")
        elif gpu_all_free:
            available_gpus = reserve_gpus
            config.wait_gpus = False
            config.visible_cuda = available_gpus[:min_count]
            config.want_gpu_num = len(config.visible_cuda)
            config.default_device = f"cuda:{config.visible_cuda[0]}"
            config.task_id = redis_client.register_gpus(config)
        else:
            # æ’é˜Ÿ
            config.task_id, wait_num = redis_client.join_wait_queue(config)
            # å‘é€é’‰é’‰é€šçŸ¥
            try:
                notice(
                    f"{config.comet_name} åŠ å…¥æ’é˜Ÿé˜Ÿåˆ—ï¼å‰æ–¹è¿˜æœ‰{wait_num}ä¸ªä»»åŠ¡ğŸš¶ğŸ»â€ğŸ§‘ğŸ»â€ğŸ¦¼ğŸš¶ğŸ‘©â€ğŸ¦¯ğŸ‘¨ğŸ»â€ğŸ¦¯", config)
            except Exception as e:
                print_error_info(e)
                log.info(f"å‘é€é’‰é’‰é€šçŸ¥å¤±è´¥: {e}")
    else:
        # ä½¿ç”¨CPU
        pass

    ###############################################
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…Gpu
    ###############################################
    while config.use_gpu and config.wait_gpus:
        curr_time = str(time.strftime('%mæœˆ%dæ—¥ %H:%M:%S', time.localtime()))
        # åˆ¤æ–­å½“å‰æ˜¯å¦è½®åˆ°è‡ªå·±
        if redis_client.is_my_turn(config):
            # å¾ªç¯è·å–å½“å‰å¯ç”¨Gpu
            try:
                min_count = config.want_gpu_num
                gpus = select_devices(
                    format="index",
                    min_count=min_count,
                    min_free_memory=config.cuda_min_free_memory,
                    max_memory_utilization=config.cuda_max_memory_utilization,
                )
                self_occupied_gpus = redis_client.get_self_occupied_gpus()

                # åœ¨ä¸è¶…å‡º GPU ä½¿ç”¨æ•°é‡é™åˆ¶ä¸‹è¿›è¡Œåˆ¤æ–­
                if len(self_occupied_gpus) < config.limit_the_amount_of_gpu_you_can_use:
                    if not isinstance(config.visible_cuda, str):
                        # å¦‚æœæŒ‡å®šäº†GPU
                        reserve_gpus = [
                            i for i, _ in enumerate(config.visible_cuda)]
                        gpu_all_free = True
                        for gpu in reserve_gpus:
                            if Device.cuda.from_cuda_indices(gpu)[0].physical_index in self_occupied_gpus:
                                gpu_all_free = False
                        if gpu_all_free:
                            available_gpus = reserve_gpus
                        else:
                            available_gpus = []
                        min_count = len(reserve_gpus)
                    else:
                        # è‡ªåŠ¨é€‰æ‹©
                        available_gpus = list(set(gpus) - self_occupied_gpus)

                    if len(available_gpus) > 0 and len(available_gpus) >= min_count:
                        # è‡ªåŠ¨é€‰æ‹©ï¼Œç¡®è®¤ç­‰å¾…
                        if (
                            config.confirm_gpu_free
                            and config.last_confirm_gpus == available_gpus[:min_count]
                        ):
                            # å¦‚æœæ»¡è¶³æ¡ä»¶é€€å‡ºå¾ªç¯
                            log.info("å‘ç°è¶³å¤Ÿå¯ç”¨GPUå¹¶äºŒæ¬¡ç¡®è®¤æˆåŠŸï¼")
                            config.wait_gpus = False
                            config.visible_cuda = available_gpus[:min_count]
                            config.want_gpu_num = len(config.visible_cuda)
                            config.default_device = f"cuda:{config.visible_cuda[0]}"
                            redis_client.pop_wait_queue(config)
                            config.task_id = redis_client.register_gpus(config)
                            break
                        else:
                            # è®¾ç½®å•æ¬¡ç¡®è®¤ç©ºé—²
                            log.info("\nå‘ç°è¶³å¤Ÿå¯ç”¨GPUï¼å³å°†è¿›è¡ŒäºŒæ¬¡ç¡®è®¤ï¼")
                            config.confirm_gpu_free = True
                            config.last_confirm_gpus = available_gpus[:min_count]
                            redis_client.update_queue(config)
                            time.sleep(30)
                            continue
                # é‡ç½®ç¡®è®¤ä¿¡æ¯
                print(f"\r{curr_time}: å½“å‰æ— è¶³å¤Ÿå¯ç”¨GPUï¼Œç»§ç»­ç­‰å¾…......",
                      end='',  flush=True)
                if config.confirm_gpu_free:
                    log.info("äºŒæ¬¡ç¡®è®¤å¤±è´¥ï¼Œç»§ç»­ç­‰å¾…......")
                config.confirm_gpu_free = False
                config.last_confirm_gpus = []
                redis_client.update_queue(config)
                time.sleep(30)
            except Exception as e:
                print_error_info(e)
                raise e
        else:
            # æ’é˜Ÿing......
            wait_num = len(redis_client.client.lrange("wait_queue", 0, -1)) - 1
            print(f"\r{curr_time}: æ­£åœ¨æ’é˜Ÿä¸­ï¼ å‰æ–¹è¿˜æœ‰ {wait_num} ä¸ªè®­ç»ƒä»»åŠ¡ï¼",
                  end='',  flush=True)
            time.sleep(60)

    if config.use_gpu:
        log.info("å®éªŒæ ‡è¯†ï¼š " + config.task_full_name)
        log.info("å®éªŒå¤‡æ³¨ï¼š " + config.memo)
        log.info("æ­£åœ¨æœé›†å¯ç”¨GPUä¿¡æ¯")
        print_gpu_info(config.visible_cuda)

    return config


class RedisClient:
    def __init__(self):
        self.client = Redis(
            host="127.0.0.1",
            port=6379,
            decode_responses=True,
            charset="UTF-8",
            encoding="UTF-8",
        )

    def get_self_occupied_gpus(self, only_gpus=True):
        """
        è·å–è‡ªå·±å·²ç»å ç”¨çš„Gpuåºå·
        """
        self_occupied_gpus = self.client.hgetall("self_occupied_gpus")
        if only_gpus:
            all_gpus = []
            for task in self_occupied_gpus.values():
                gpus = [
                    int(device) for device in str(json.loads(task)["cuda_devices"]).split(",")
                ]
                all_gpus.extend(gpus)
            return set(all_gpus)
        return [json.loads(g) for g in self_occupied_gpus.values()]

    def join_wait_queue(self, config):
        """
        åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")
        task_id = (
            str(os.getpid())
            + "*"
            + str(int(time.mktime(time.strptime(creat_time, "%Y-%m-%d %H:%M:%S"))))
        )
        cuda_devices = ','.join([str(cuda) for cuda in config.visible_cuda]) if isinstance(
            config.visible_cuda, list) else "auto"
        content = {
            "want_gpus": config.want_gpu_num,
            "cuda_devices": cuda_devices,
            "create_time": creat_time,
            "update_time": creat_time,
            "system_pid": os.getpid(),
            "task_id": task_id,
            "run_name": config.comet_name,
            "comet_name": config.comet_name,
            "logger_project": config.logger_project,
            "memo": config.memo,
        }
        wait_num = len(self.client.lrange("wait_queue", 0, -1))
        self.client.rpush("wait_queue", json.dumps(content))
        if wait_num == 0:
            log.info(f"æ­£åœ¨æ’é˜Ÿä¸­ï¼ ç›®å‰æ’ç¬¬ä¸€ä½å“¦ï¼")
        else:
            log.info(f"æ­£åœ¨æ’é˜Ÿä¸­ï¼ å‰æ–¹è¿˜æœ‰ {wait_num} ä¸ªè®­ç»ƒä»»åŠ¡ï¼")
        log.info(
            f"tips: å¦‚æœæƒ³è¦å¯¹ä»»åŠ¡è¿›è¡Œè°ƒæ•´å¯ä»¥ç§»æ­¥Rediså®¢æˆ·ç«¯è¿›è¡Œæ•°æ®ä¿®æ”¹ï¼Œåªå»ºè®®è¿›è¡Œä¿®æ”¹ want_gpus å‚æ•°ä»¥åŠåˆ é™¤è®­ç»ƒä»»åŠ¡æ“ä½œï¼Œå…¶ä»–æ“ä½œå¯èƒ½ä¼šå½±å“Redisè¯»å–çš„ç¨³å®šæ€§"
        )
        return task_id, wait_num

    def is_my_turn(self, config):
        """
        æ’é˜Ÿè¿™ä¹ˆé•¿æ—¶é—´ï¼Œæ˜¯å¦è½®åˆ°æˆ‘äº†ï¼Ÿ
        """
        curr_task = json.loads(self.client.lrange("wait_queue", 0, -1)[0])
        return curr_task["task_id"] == config.task_id

    def update_queue(self, config):
        """
        æ›´æ–°ç­‰å¾…é˜Ÿåˆ—
        """
        task = json.loads(self.client.lrange("wait_queue", 0, -1)[0])
        if task["task_id"] != config.task_id:
            # ç™»è®°å¼‚å¸¸ä¿¡æ¯
            log.info("å½“å‰è®­ç»ƒä»»åŠ¡å¹¶ä¸æ’åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œè¯·æ£€æŸ¥Redisæ•°æ®æ­£ç¡®æ€§ï¼")
        curr_time = datetime.datetime.now()
        update_time = datetime.datetime.strftime(
            curr_time, "%Y-%m-%d %H:%M:%S")
        task["update_time"] = update_time
        self.client.lset("wait_queue", 0, json.dumps(task))
        # log.info("æ›´æ–°è®­ç»ƒä»»åŠ¡æ—¶é—´æˆ³æˆåŠŸï¼")

    def pop_wait_queue(self, config):
        """
        å¼¹å‡ºå½“å‰æ’ä½ç¬¬ä¸€çš„è®­ç»ƒä»»åŠ¡
        """
        task = json.loads(self.client.lrange("wait_queue", 0, -1)[0])
        if task["task_id"] != config.task_id:
            # ç™»è®°å¼‚å¸¸ä¿¡æ¯
            log.info("å½“å‰è®­ç»ƒä»»åŠ¡å¹¶ä¸æ’åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œè¯·æ£€æŸ¥Redisæ•°æ®æ­£ç¡®æ€§ï¼")
        next_task = self.client.lpop("wait_queue")
        return next_task

    def register_gpus(self, config):
        """
        å°†å½“å‰è®­ç»ƒä»»åŠ¡ç™»è®°åˆ°GPUå ç”¨ä¿¡æ¯ä¸­
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")
        if not config.task_id:
            task_id = (
                str(os.getpid())
                + "*"
                + str(int(time.mktime(time.strptime(creat_time, "%Y-%m-%d %H:%M:%S"))))
            )
        else:
            task_id = config.task_id

        content = {
            "use_gpus": config.want_gpu_num,
            "cuda_devices": ",".join([str(Device.cuda.from_cuda_indices(gpu)[0].physical_index) for gpu in list(config.visible_cuda)]),
            "register_time": datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S"),
            "system_pid": os.getpid(),
            "task_id": task_id,
            "run_name": config.comet_name,
            "comet_name": config.comet_name,
            "logger_project": config.logger_project,
            "memo": config.memo,
        }
        self.client.hset("self_occupied_gpus", task_id, json.dumps(content))
        log.info("æˆåŠŸç™»è®°Gpuä½¿ç”¨ä¿¡æ¯åˆ°RedisæœåŠ¡å™¨ï¼")
        return task_id

    def deregister_gpus(self, config):
        """
        åˆ é™¤å½“å‰è®­ç»ƒä»»åŠ¡çš„å ç”¨ä¿¡æ¯
        """
        task = self.client.hget("self_occupied_gpus", config.task_id)
        if task:
            self.client.hdel("self_occupied_gpus", config.task_id)
            log.info("æˆåŠŸåˆ é™¤RedisæœåŠ¡å™¨ä¸Šçš„Gpuä½¿ç”¨ä¿¡æ¯ï¼")
        else:
            log.info("æ— æ³•æ‰¾åˆ°å½“å‰è®­ç»ƒä»»åŠ¡åœ¨RedisæœåŠ¡å™¨ä¸Šçš„Gpuä½¿ç”¨ä¿¡æ¯ï¼æˆ–è®¸å¯ä»¥è€ƒè™‘æ£€æŸ¥ä¸€ä¸‹Redisçš„æ•°æ® ğŸ¤”")

    def register_process(self, config):
        """
        å°†å½“å‰è®­ç»ƒä»»åŠ¡ç™»è®°åˆ°è¿›ç¨‹ä¿¡æ¯ä¸­
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S")
        if not config.task_id:
            task_id = (
                str(os.getpid())
                + "*"
                + str(int(time.mktime(time.strptime(creat_time, "%Y-%m-%d %H:%M:%S"))))
            )
        else:
            task_id = config.task_id

        content = {
            "use_gpus": config.want_gpu_num,
            "memo": config.memo,
            "see_log": "tail -f " + config.get("see_log", "å½“å‰è¿›ç¨‹æœªä½¿ç”¨ nohup å‘½ä»¤å¯åŠ¨ï¼Œæ— æ³•æŸ¥çœ‹æ—¥å¿—"),
            "register_time": datetime.datetime.strftime(curr_time, "%Y-%m-%d %H:%M:%S"),
            "system_pid": os.getpid(),
            "task_id": task_id,
            "run_name": config.comet_name,
            "comet_name": config.comet_name,
            "logger_project": config.logger_project,
        }
        self.client.hset("running_processes", task_id, json.dumps(content))
        log.info("æˆåŠŸç™»è®°è¿›ç¨‹ä½¿ç”¨ä¿¡æ¯åˆ°RedisæœåŠ¡å™¨ï¼")
        return task_id

    def deregister_process(self, config):
        """
        åˆ é™¤å½“å‰è®­ç»ƒä»»åŠ¡çš„ä¿¡æ¯
        """
        task = self.client.hget("running_processes", config.task_id)
        if task:
            self.client.hdel("running_processes", config.task_id)
            log.info("æˆåŠŸåˆ é™¤RedisæœåŠ¡å™¨ä¸Šçš„è¿›ç¨‹ä½¿ç”¨ä¿¡æ¯ï¼")
        else:
            log.info("æ— æ³•æ‰¾åˆ°å½“å‰è®­ç»ƒä»»åŠ¡åœ¨RedisæœåŠ¡å™¨ä¸Šçš„è¿›ç¨‹ä½¿ç”¨ä¿¡æ¯ï¼æˆ–è®¸å¯ä»¥è€ƒè™‘æ£€æŸ¥ä¸€ä¸‹Redisçš„æ•°æ® ğŸ¤”")



def print_gpu_info(gpus):
    # or `Device.all()` to use NVML ordinal instead
    devices = Device.cuda.from_cuda_indices(gpus)
    separator = False
    for device in devices:
        processes = device.processes()
        print(colored(str(device), color="green", attrs=("bold",)))
        print(
            colored("  - GPU physical index: ", color="blue", attrs=("bold",))
            + f"{device.physical_index}"
        )
        print(
            colored("  - GPU utilization: ", color="blue", attrs=("bold",))
            + f"{device.gpu_utilization()}%"
        )
        print(
            colored("  - Total memory:    ", color="blue", attrs=("bold",))
            + f"{device.memory_total_human()}"
        )
        print(
            colored("  - Used memory:     ", color="blue", attrs=("bold",))
            + f"{device.memory_used_human()}"
        )
        print(
            colored("  - Free memory:     ", color="blue", attrs=("bold",))
            + f"{device.memory_free_human()}"
        )

        if len(processes) > 0:
            processes = GpuProcess.take_snapshots(
                processes.values(), failsafe=True)
            processes.sort(key=lambda process: (process.username, process.pid))

            print(
                colored(
                    f"  - Processes ({len(processes)}):", color="blue", attrs=("bold",)
                )
            )
            fmt = "    {pid:<5}  {username:<8} {cpu:>5}  {host_memory:>8} {time:>8}  {gpu_memory:>8}  {sm:>3}  {command:<}".format
            print(
                colored(
                    fmt(
                        pid="PID",
                        username="USERNAME",
                        cpu="CPU%",
                        host_memory="HOST-MEM",
                        time="TIME",
                        gpu_memory="GPU-MEM",
                        sm="SM%",
                        command="COMMAND",
                    ),
                    attrs=("bold",),
                )
            )
            for snapshot in processes:
                print(
                    fmt(
                        pid=snapshot.pid,
                        username=snapshot.username[:7]
                        + (
                            "+"
                            if len(snapshot.username) > 8
                            else snapshot.username[7:8]
                        ),
                        cpu=snapshot.cpu_percent,
                        host_memory=snapshot.host_memory_human,
                        time=snapshot.running_time_human,
                        gpu_memory=(
                            snapshot.gpu_memory_human
                            if snapshot.gpu_memory_human is not NA
                            else "WDDM:N/A"
                        ),
                        sm=snapshot.gpu_sm_utilization,
                        command=snapshot.command,
                    )
                )
        else:
            print(colored("  - No Running Processes", attrs=("bold",)))
        if separator:
            print("-" * 120)
        separator = True
